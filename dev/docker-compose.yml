# run docker-compose build from inside the directory docker-compose.yml is. build context is defined relative to the docker-compose.yml file
version: "3.7"
services:

  redis:
    image: redis:7.0-bullseye
    ports:
      - "6379:6379"

  rabbitmq:
    image: rabbitmq:3.11.9-management
    ports:
      - "5672:5672"
      - "15672:15672"

  payments:
    build:
      context: ../../payments/payments_src  # relative to the docker-compose.yml file
      dockerfile: dev_container/Dockerfile  # the Dockerfile path is relative to the build context
    volumes:
      # the from path is the path of the folder in the VM (so it has to be shared with windows first)
      # the to path is the path of the folder in the container (the WORKDIR of the Dockerfile)
      - /web_ai/payments/payments_src/:/usr/src/payments_src
    expose:
      - 8001 # Exposes ports without publishing them to the host machine, they’ll only be accessible to linked services
    ports:
      - "8001:8001"  # host:container
    depends_on:
      - rabbitmq
    env_file:
      - ../../payments/payments_src/.env

  pre_inference:
    build:
      context: ../../pre_inference/pre_inference_src  # relative to the docker-compose.yml file
      dockerfile: dev_container/Dockerfile  # the Dockerfile path is relative to the build context
    volumes:
      # the from path is the path of the folder in the VM (so it has to be shared with windows first)
      # the to path is the path of the folder in the container (the WORKDIR of the Dockerfile)
      - /web_ai/pre_inference/pre_inference_src:/usr/src/pre_inference_src
    expose:
      - 8002 # Exposes ports without publishing them to the host machine, they’ll only be accessible to linked services
    ports:
      - "8002:8002"  # host:container
    depends_on:
      - redis
    env_file:
      - ../../pre_inference/pre_inference_src/.env
    environment:
      WATCHFILES_FORCE_POLLING: 1


  auth:
    build:
      context: ../../auth/auth_src  # relative to the docker-compose.yml file
      dockerfile: dev_container/Dockerfile  # the Dockerfile path is relative to the build context
    volumes:
      # the from path is the path of the folder in the VM (so it has to be shared with windows first)
      # the to path is the path of the folder in the container (the WORKDIR of the Dockerfile)
      - /web_ai/auth/auth_src:/usr/src/auth_src
    expose:
      - 8000 # Exposes ports without publishing them to the host machine, they’ll only be accessible to linked services
    ports:
      - "8000:8000"  # host:container
    depends_on:
      - rabbitmq
    env_file:
      - ../../auth/auth_src/.env

  web_client:
    build:
      context: ../../web_client/web_client_src  # relative to the docker-compose.yml file
      dockerfile: dev_container/Dockerfile  # the Dockerfile path is relative to the build context
    volumes:
      # the from path is the path of the folder in the VM (so it has to be shared with windows first)
      # the to path is the path of the folder in the container (the WORKDIR of the Dockerfile)
      - /web_ai/web_client/web_client_src:/usr/src/web_client_src
    expose:
      - 3000 # Exposes ports without publishing them to the host machine, they’ll only be accessible to linked services
    ports:
      - "3000:3000"  # host:container
    stdin_open: true  # allows to run the container in interactive mode. (it solves the exit with code 0 issue: https://github.com/facebook/create-react-app/issues/8688)
    env_file:
      - ../../web_client/web_client_src/.env
    environment:
      # CHOKIDAR_USEPOLLING=true is needed for hot reloading on container running in docker-machine on windows host
      CHOKIDAR_USEPOLLING: 1

  #  model_scheduler:
  ##    build:
  ##      context: ../../model_scheduler/model_scheduler_src  # relative to the docker-compose.yml file
  ##      dockerfile: dev_container/Dockerfile  # the Dockerfile path is relative to the build context
  #    image: dimyg/web_ai:model_1_runpod
  #    volumes:
  #      # the from path is the path of the folder in the VM (so it has to be shared with windows first)
  #      # the to path is the path of the folder in the container (the WORKDIR of the Dockerfile)
  #      - /web_ai/model_scheduler/model_scheduler_src
  #    expose:
  #      - 8001 # Exposes ports without publishingthem to the host machine, they’ll only be accessible to linked services
  #    ports:
  #      - "8001:8001"  # host:container
  #    env_file:
  #      - ../../model_scheduler/model_scheduler_src/.env
  #    environment:
  #      DEBUG: 1
  #      WATCHFILES_FORCE_POLLING: 1
  #    the values of the environment directive override the values of the env-file directive
  #    environment:
  #      HUGGINGFACE_ACCESS_TOKEN: ${HUGGINGFACE_ACCESS_TOKEN}
  #      PYTORCH_CUDA_ALLOC_CONF: ${PYTORCH_CUDA_ALLOC_CONF}
  #      HUGGINGFACE_HUB_CACHE: ${HUGGINGFACE_HUB_CACHE}